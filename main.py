import pandas as pd
import glob
import os
import re
import json
# æ˜¾å¼å¯¼å…¥ï¼Œç¡®ä¿ç¯å¢ƒèƒ½æ‰¾åˆ°å®ƒ
try:
    import tabulate
except ImportError:
    print("\né”™è¯¯: æœªæ‰¾åˆ° tabulate åº“ã€‚")
    print("è¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…: py -m pip install tabulate")
    exit(1)

def analyze_wmi_diff():
    # --- é…ç½®åŒºåŸŸ ---
    file_pattern = "WmiDoc_Final_*_WithEnums.csv"
    alias_file = "wmi_alias.json"
    output_xlsx = "WMI_Version_Comparison_Report.xlsx"
    output_csv = "WMI_Version_Comparison_Report.csv"
    docs_dir = "docs"

    # 1. è·å– CSV æ–‡ä»¶
    file_list = glob.glob(file_pattern)
    if not file_list:
        print("é”™è¯¯: å½“å‰ç›®å½•ä¸‹æœªæ‰¾åˆ°åŒ¹é…çš„ CSV æ–‡ä»¶ï¼")
        return

    # 2. åŠ è½½ç¿»è¯‘æ˜ å°„è¡¨
    translations = {}
    if os.path.exists(alias_file):
        try:
            with open(alias_file, "r", encoding="utf-8") as f:
                translations = json.load(f)
            print(f"æˆåŠŸåŠ è½½ç¿»è¯‘å­—å…¸ï¼ŒåŒ…å« {len(translations)} æ¡æ˜ å°„è§„åˆ™ã€‚")
        except Exception as e:
            print(f"è¯»å– JSON å¤±è´¥: {e}")

    all_dfs = []
    version_list = []

    # 3. è¯»å–æ•°æ®
    for file_path in file_list:
        filename = os.path.basename(file_path)
        match = re.search(r"WmiDoc_Final_(\d+)_WithEnums", filename)
        if match:
            build_num = match.group(1)
            print(f"è¯»å–ç‰ˆæœ¬: {build_num}")
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            df['Version'] = build_num
            all_dfs.append(df)
            version_list.append(build_num)

    # 4. åˆå¹¶ä¸æ’åº
    full_df = pd.concat(all_dfs, ignore_index=True)
    sorted_versions = sorted(version_list, key=int, reverse=True)

    # 5. æå–å…ƒæ•°æ® (åŸºäºæœ€é«˜ç‰ˆæœ¬)
    full_df['Version_Int'] = full_df['Version'].astype(int)
    metadata = full_df.sort_values('Version_Int').drop_duplicates(subset=['Class', 'Member'], keep='last').copy()

    # å¤„ç†æè¿°
    metadata.rename(columns={'Desc': 'Desc_EN'}, inplace=True)
    def get_translated_desc(row):
        mapping_key = f"{row['Class']}:{row['Member']}"
        return translations.get(mapping_key, row['Desc_EN'])

    print("æ­£åœ¨åº”ç”¨ç¿»è¯‘...")
    metadata['Desc'] = metadata.apply(get_translated_desc, axis=1)

    if 'Access' not in metadata.columns:
        metadata['Access'] = metadata.apply(lambda r: "Method" if r['Category'] == 'Method' else "Property", axis=1)

    # 6. é€è§†è¡¨ç”Ÿæˆ
    pivot = full_df.pivot_table(index=['Class', 'Member'], columns='Version', aggfunc='size', fill_value=0)
    for col in pivot.columns:
        pivot[col] = pivot[col].apply(lambda x: "âœ…" if x > 0 else "âŒ")

    # 7. åˆå¹¶æœ€ç»ˆç»“æœ
    result = metadata.merge(pivot, on=['Class', 'Member'], how='left')

    # 8. æ•´ç†åˆ—é¡ºåº
    base_cols = ['Class', 'Member', 'Type', 'Category', 'Access']
    final_cols = base_cols + sorted_versions + ['Desc', 'Desc_EN']
    result = result[[c for c in final_cols if c in result.columns]]

    # 9. å¯¼å‡º Master XLSX
    print(f"æ­£åœ¨å¯¼å‡º Master Excel: {output_xlsx}")
    try:
        with pd.ExcelWriter(output_xlsx, engine='openpyxl') as writer:
            result.to_excel(writer, index=False, sheet_name='WMIå¯¹æ¯”å·®å¼‚')
            ws = writer.sheets['WMIå¯¹æ¯”å·®å¼‚']
            ws.auto_filter.ref = ws.dimensions
            ws.freeze_panes = "C2"
            for i, col in enumerate(result.columns):
                col_letter = ws.cell(row=1, column=i+1).column_letter
                ws.column_dimensions[col_letter].width = 100 if 'Desc' in col else 22
    except Exception as e:
        print(f"Excel å¯¼å‡ºå¤±è´¥: {e}")

    # 10. å¯¼å‡º Master CSV
    print(f"æ­£åœ¨å¯¼å‡º Master CSV: {output_csv}")
    result.to_csv(output_csv, index=False, encoding='utf-8-sig')

    # 11. æ‹†åˆ†ç”Ÿæˆ MD
    print(f"æ­£åœ¨æ‹†åˆ†ç”Ÿæˆä¸ªä½“æ–‡æ¡£ (docs/)...")
    if not os.path.exists(docs_dir):
        os.makedirs(docs_dir)

    index_list = []
    grouped = result.groupby('Class')
    
    total_classes = len(grouped)
    current_count = 0

    for class_name, group in grouped:
        current_count += 1
        if current_count % 50 == 0:
            print(f"è¿›åº¦: {current_count}/{total_classes} ç±»å·²å¤„ç†...")

        sub_group = group.drop(columns=['Class'])
        safe_name = "".join([c for c in class_name if c.isalnum() or c == '_']).strip()
        md_filename = f"{safe_name}.md"
        md_path = os.path.join(docs_dir, md_filename)
        
        index_list.append(f"- [{class_name}](./{docs_dir}/{md_filename})")

        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(f"# WMI Class: {class_name}\n\n")
            f.write(f"[â¬…ï¸ è¿”å›ç±»ç´¢å¼•](../README_INDEX.md) | [ğŸ“Š ä¸‹è½½å…¨é‡è¡¨ CSV](../{output_csv})\n\n")
            f.write(f"## æˆå‘˜åˆ—è¡¨ä¸å…¼å®¹æ€§æŠ¥å‘Š\n\n")
            # å¯¼å‡ºä¸º MD è¡¨æ ¼
            f.write(sub_group.to_markdown(index=False))
            f.write(f"\n\n---\n*æ•°æ®è‡ªåŠ¨ç”Ÿæˆäº: {pd.Timestamp.now().strftime('%Y-%m-%d')}*")

    # 12. ç”Ÿæˆç´¢å¼•é¡µ
    print("æ­£åœ¨ç”Ÿæˆ README_INDEX.md...")
    index_list.sort()
    with open("README_INDEX.md", 'w', encoding='utf-8') as f:
        f.write("# WMI ç±»å¿«é€Ÿç´¢å¼•\n\n")
        f.write(f"æœ¬ä»“åº“å…±åŒ…å« {total_classes} ä¸ª WMI ç±»ã€‚ç‚¹å‡»ä¸‹æ–¹ç±»åæŸ¥çœ‹è¯¦ç»†å±æ€§ä¸ç‰ˆæœ¬å…¼å®¹æ€§æŠ¥å‘Šã€‚\n\n")
        f.write("\n".join(index_list))
        f.write("\n\n---\n[ğŸ”™ è¿”å›ä¸»é¡µ](./README.md)")

    print(f"\næˆåŠŸï¼å­æ–‡æ¡£å·²ç”Ÿæˆåœ¨ {docs_dir}/ æ–‡ä»¶å¤¹ä¸‹ã€‚")

if __name__ == "__main__":
    analyze_wmi_diff()